#!/usr/bin/python3

import os
import sys
import csv
import re
from datetime import datetime

"""
Extracts graphs generated by GaussianCluster.
The graphs is formatted into two files: nodesFile and edgesFile containing data for nodes and edges respectively.

Output of GaussianCluster should contain multiple graphs marked by graphNodeStartStr, graphEdgeStartStr and graphEndStr.
Between the lines containing graphNodeStartStr and graphEdgeStartStr is a valid csv-file containg all nodes.
Between the lines containing graphEdgeStartStr and graphEndStr is a valid csv-file containg all edges.

All graphs are combined into one graph. Some special attributes stay the same across all graphs.
Other attributes are combined into the format "<[0,1,value1);[1,2,value2);...;[N-1,N,valueN)>".
"""

# ---------------------------------------------- Constants ---------------------------------------------

# marks the start of nodes data
graphNodeStartStr = 'GaussianCluster Graph: Nodes'
# marks the end of nodes and start of edge data
graphEdgeStartStr = 'GaussianCluster Graph: Edges'
# marks end of edge data
graphEndStr = 'GaussianCluster Graph: End'

# special headers
idStr = 'id'
timesetStr = 'timeset'
labelStr = 'Label'
sourceStr = 'Source'
targetStr = 'Target'

# output file names
nodesFile = 'graphNodes.csv'
edgesFile = 'graphEdges.csv'

# -------------------------------------------- Functions --------------------------------------------

def printHelp():
    print("Usage: ./extractClusterGraph.py path/To/mdFlex/std.out [path/To/mdFelx/fullsearch/std.out]")
    print("If FullSearch is provided, measured runtimes will be added to the nodes")
    sys.exit(0)

def getStringFromLines(lines, regex):
    """extracts first capturing group of first line matching regex"""
    for line in lines:
        match = re.search(regex, line)
        if match:
            return match.group(1)

def getLabelDict(label):
    """
    Given label of form: { key1 : value1 , key2 : value 2 , ... }
    e.g. {Container: LinkedCells , CellSizeFactor: 2.000000 , Traversal: c08 , Data Layout: AoS , Newton 3: disabled}
    This function returns all key:value pairs as dict.
    """
    result = {}
    keyValues = re.search('{(.*)}', label)[1].split(',') # remove outer brackets and split by comma
    for keyValue in keyValues:
        key, value = keyValue.split(':')
        result[key.strip()] = value.strip()
        
    return result

def getID(label):
    """get a unique id for a label"""
    # if label not seen before, generate new id
    if not label in getID.labelDict:
        getID.labelDict[label] = len(getID.labelDict)
        
    return getID.labelDict[label]

getID.labelDict = {}
    

# ---------------------------------------------- Input ----------------------------------------------

# help message
for arg in sys.argv[1:]:
    if "--help" in arg:
        printHelp()

# first file contains graph
if len(sys.argv) > 1:
    graphFile = sys.argv[1]
else:
    printHelp()

# second file contains optional full search
fullSearchFile = None
if len(sys.argv) > 2:
    fullSearchFile = sys.argv[2]

# directory for graph output
outputDir="clusterGraph_"+datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

# ---------------------------------------------- Classes ---------------------------------------------

class GraphNode:
    """Class to store a node"""
    def __init__(self, label):
        self.id = str(getID(label))
        self.label = label
        self.timeValues = {}
        
    def getRow(self, nodeHeaders, labelHeaders):
        """
        Convert node to csv row.
        Columns: id, Label, timeset, configurations... , remaining headers...
        """
        # initialize empty list for each header
        columns = {header:[] for header in nodeHeaders}
            
        # collect time-value-pairs for each header
        for time,values in self.timeValues.items():
            for header,value in values.items():
                columns[header].append((time,time+1,value))
    
        # first rows: id, Label
        row = [self.id, self.label]
        
        # timeset format: <[time1,time1+1);[time2,time2+1);...;[timeN,timeN+1)>
        row.append('<{}>'.format(';'.join(['[{:d},{:d})'.format(time,time+1) for time in self.timeValues.keys()])))
        
        # extract label information
        configurations = getLabelDict(self.label)
        for header in labelHeaders:
            row.append(configurations[header])
        
        for header in nodeHeaders:
            # print each column in format: <[time1,time1+1,value1);[time2,time2+1,value2);...;[timeN,timeN+1,valueN)>
            row.append('<{}>'.format(';'.join(['[{:d},{:d},{})'.format(*interval) for interval in columns[header]])))
            
        return row
        
class GraphEdge:
    """Class to store a edge"""
    def __init__(self, src, target):
        self.src = src
        self.target = target
        self.timeValues = {}
        
    def getRow(self, headers):
        """
        Convert edge to csv row
        Columns: Source, Target, timeset, remaining headers...
        """
        # initialize empty list for each header
        columns = {header:[] for header in headers}
            
        # collect time-value-pairs for each header
        for time,values in self.timeValues.items():
            for header,value in values.items():
                columns[header].append((time,time+1,value))
    
        # first rows: Source, Target
        row = [str(self.src), str(self.target)]
        
        # timeset format: <[time1,time1+1);[time2,time2+1);...;[timeN,timeN+1)>
        row.append('<{}>'.format(';'.join(['[{:d},{:d})'.format(time,time+1) for time in self.timeValues.keys()])))

        for header in headers:
            # print each column in format: <[time1,time1+1,value1);[time2,time2+1,value2);...;[timeN,timeN+1,valueN)>
            row.append('<{}>'.format(';'.join(['[{:d},{:d},{})'.format(*interval) for interval in columns[header]])))
            
        return row

# ---------------------------------------------- Script ---------------------------------------------

graphNodeStartPos = []
graphEdgeStartPos = []
graphEndPos = []

# parse file
with open(graphFile) as f:
    lines = f.readlines()

# get lines containing markers
for i,line in enumerate(lines):
    if graphNodeStartStr in line:
        graphNodeStartPos.append(i)
    elif graphEdgeStartStr in line:
        graphEdgeStartPos.append(i)
    elif graphEndStr in line:
        graphEndPos.append(i)

# check that all markers appear equally often
if (not len(graphNodeStartPos) == len(graphEdgeStartPos) == len(graphEndPos)):
    print('Error: number of markers not equal! Node {:d}, Edge {:d}, End {:d}.'.format(len(graphNodeStartPos), len(graphEdgeStartPos), len(graphEndPos)))
    sys.exit(1)
    
numGraphs = len(graphNodeStartPos)
graphPos = [(graphNodeStartPos[i], graphEdgeStartPos[i], graphEndPos[i]) for i in range(numGraphs)]
    
# check that all markers repeatedly appear in order: node, edge, end
if (not all([node < edge < end for (node, edge, end) in graphPos])) or (not all([(graphEndPos[i-1] < graphEdgeStartPos[i]) for i in range(1,numGraphs)])):
    print('Error: unexpected order of markers!')
    sys.exit(1)


# ------ read all graphs ------
nodes = {}
nodeHeaders = set()
edges = {}
edgeHeaders = set()
for i,(nodeStart, edgeStart, graphEnd) in enumerate(graphPos):
    print('Graph found from line {:d} to {:d}'.format(nodeStart, graphEnd))
    
    # ----- read nodes -----
    nodesReader = csv.reader(lines[nodeStart+1:edgeStart], delimiter=',', quotechar='"')
    
    # find index labels
    header = next(nodesReader)
    for c,column in enumerate(header):
        if column == labelStr:
            labelIndex = c
        else:
            nodeHeaders.add(column)
    
    for row in nodesReader:
        if (row):
            # get values of current row
            values = { }
            for c,column in enumerate(header):
                value = row[c]
                
                # get Label seperately. Rest in dict values.
                if c == labelIndex:
                    label = value
                else:
                    values[column] = value
            
            nodeId = getID(label)
            
            # create new node if not already
            if not nodeId in nodes:
                nodes[nodeId] = GraphNode(label)
                
            nodes[nodeId].timeValues[i] = values
    
    # ----- read edges -----
    edgeReader = csv.reader(lines[edgeStart+1:graphEnd], delimiter=',', quotechar='"')
    
    # find index of src and target
    header = next(edgeReader)
    for c,column in enumerate(header):
        if column == sourceStr:
            srcIndex = c
        elif column == targetStr:
            targetIndex = c
        else:
            edgeHeaders.add(column)
    
    for row in edgeReader:
        if (row):
            # get values of current row
            values = { }
            for c,column in enumerate(header):
                value = row[c]
                
                # get Source and Target seperately and convert them to unique ids. Rest in dict values.
                if c == srcIndex:
                    src = getID(value)
                elif c == targetIndex:
                    target = getID(value)
                else:
                    values[column] = value
            
            # create new edge if not already exists
            if not (src,target) in edges:
                edges[src,target] = GraphEdge(src, target)
                
            edges[src,target].timeValues[i] = values
                
                
# convert header sets to lists
nodeHeaders = list(nodeHeaders)
edgeHeaders = list(edgeHeaders)

# Labels are used configuration: e.g. {Container: LinkedCells , CellSizeFactor: 2.000000 , Traversal: c08 , Data Layout: AoS , Newton 3: disabled}
# Extract header names
labelHeaders = list(getLabelDict(nodes[0].label).keys())
    
# ---- Write files ----

# create output directory
try:
    os.makedirs(outputDir)
except OSError:
    print('Could not create the output directory: ' + outputDir)
    sys.exit(2)
    
allNodeHeaders = [idStr, labelStr, timesetStr] + labelHeaders + nodeHeaders
allEdgeHeaders = [sourceStr, targetStr, timesetStr] + edgeHeaders
    
if (fullSearchFile):
    # if fullSearchFile given, append time found in this file to each row
    
    with open(fullSearchFile) as f:
        fullSearchLines = f.readlines()
    
    with open(os.path.join(outputDir, nodesFile), 'w', newline='') as f:
        nodesWriter = csv.writer(f, delimiter=',', quotechar='"')
        nodesWriter.writerow(allNodeHeaders + ['runtime'])
        for node in nodes.values():
            row = node.getRow(nodeHeaders, labelHeaders)
            
            # extract label from row and find corresponding runtime in fullSearchFile
            runtime = getStringFromLines(fullSearchLines, node.label + '.* Reduced value: ([0-9]+)')

            # append runtime to row if found otherwise discard row
            if runtime:
                row.append(runtime)
                nodesWriter.writerow(row)
            
else:
    # without fullSearchFile just write lines into file
    with open(os.path.join(outputDir, nodesFile), 'w', newline='') as f:
        nodesWriter = csv.writer(f, delimiter=',', quotechar='"')
        nodesWriter.writerow(allNodeHeaders)
        for node in nodes.values():
            nodesWriter.writerow(node.getRow(nodeHeaders, labelHeaders))

# write edges into file
with open(os.path.join(outputDir, edgesFile), 'w', newline='') as f:
    edgeWriter = csv.writer(f, delimiter=',', quotechar='"')
    edgeWriter.writerow(allEdgeHeaders)
    for edge in edges.values():
        edgeWriter.writerow(edge.getRow(edgeHeaders))