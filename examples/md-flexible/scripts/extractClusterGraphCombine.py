#!/usr/bin/python3

import os
import sys
import csv
import re
from datetime import datetime

# THIS SCRIPT NEEDS AT LEAST PYTHON 3.8.
assert sys.version_info >= (3,8)

# Extracts graphs generated by GaussianCluster.
# The graphs is formatted into two files: nodesFile and edgesFile containing data for nodes and edges respectively.
#
# Output of GaussianCluster should contain multiple graphs marked by graphNodeStartStr, graphEdgeStartStr and graphEndStr.
# Between the lines containing graphNodeStartStr and graphEdgeStartStr is a valid csv-file containg all nodes.
# Between the lines containing graphEdgeStartStr and graphEndStr is a valid csv-file containg all edges.
#
# All graphs are combined into one graph. Some special attributes stay the same across all graphs.
# Other attributes are combined into the format "<[0,1,value1);[1,2,value2);...;[N-1,N,valueN)>"

# ---------------------------------------------- Constants ---------------------------------------------

# marks the start of nodes data
graphNodeStartStr = 'GaussianCluster Graph: Nodes'
# marks the end of nodes and start of edge data
graphEdgeStartStr = 'GaussianCluster Graph: Edges'
# marks end of edge data
graphEndStr = 'GaussianCluster Graph: End'

# special headers
idStr = 'id'
timesetStr = 'timeset'
labelStr = 'Label'
sourceStr = 'Source'
targetStr = 'Target'
fullSearchTimeStr = 'runtime'

# output file names
nodesFile = 'graphNodes.csv'
edgesFile = 'graphEdges.csv'

# -------------------------------------------- Functions --------------------------------------------

def printHelp():
    print("Usage: ./extractClusterGraph.py path/To/mdFlex/std.out [path/To/mdFelx/fullsearch/std.out]")
    print("If FullSearch is provided, measured runtimes will be added to the nodes")
    sys.exit(0)

def getStringFromLines(lines, regex):
    """extracts first capturing group of first line matching regex"""
    for line in lines:
        match = re.search(regex, line)
        if match:
            return match.group(1)

def getLabelDict(label):
    """
    Given label of form: { key1 : value1 , key2 : value 2 , ... }
    e.g. {Container: LinkedCells , CellSizeFactor: 2.000000 , Traversal: c08 , Data Layout: AoS , Newton 3: disabled}
    This function returns all key:value pairs as dict.
    """
    result = {}
    keyValues = re.search('{(.*)}', label)[1].split(',') # remove outer brackets and split by comma
    for keyValue in keyValues:
        key, value = keyValue.split(':')
        result[key.strip()] = value.strip()

    return result

def getID(label):
    """get a unique id for a label"""
    # if label not seen before, generate new id
    if not label in getID.labelDict:
        getID.labelDict[label] = len(getID.labelDict)

    return getID.labelDict[label]

getID.labelDict = {}


# ---------------------------------------------- Input ----------------------------------------------

# help message
for arg in sys.argv[1:]:
    if "--help" in arg:
        printHelp()

# first file contains graph
if len(sys.argv) > 1:
    graphFile = sys.argv[1]
else:
    printHelp()

# second file contains optional full search
fullSearchFile = None
if len(sys.argv) > 2:
    fullSearchFile = sys.argv[2]

# directory for graph output
outputDir="clusterGraph_"+datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

# ---------------------------------------------- Classes ---------------------------------------------

class GraphNode:
    """Class to store a node"""
    def __init__(self, label):
        self.id = str(getID(label))
        self.label = label
        self.timeValues = {}

    def getRow(self, nodeHeaders, labelHeaders):
        """
        Convert node to csv row.
        Columns: id, Label, timeset, configurations... , remaining headers...
        """
        # initialize empty list for each header
        columns = {header:[] for header in nodeHeaders}

        # collect time-value-pairs for each header
        for time,values in self.timeValues.items():
            for header,value in values.items():
                columns[header].append((time,time+1,value))

        # first rows: id, Label
        row = [self.id, self.label]

        # timeset format: <[time1,time1+1);[time2,time2+1);...;[timeN,timeN+1)>
        row.append('<{}>'.format(';'.join(['[{:d},{:d})'.format(time,time+1) for time in self.timeValues.keys()])))

        # extract label information
        configurations = getLabelDict(self.label)
        for header in labelHeaders:
            row.append(configurations[header])

        for header in nodeHeaders:
            # print each column in format: <[time1,time1+1,value1);[time2,time2+1,value2);...;[timeN,timeN+1,valueN)>
            row.append('<{}>'.format(';'.join(['[{:d},{:d},{})'.format(*interval) for interval in columns[header]])))

        return row

class GraphEdge:
    """Class to store a edge"""
    def __init__(self, src, target):
        self.src = src
        self.target = target
        self.timeValues = {}

    def getRow(self, headers):
        """
        Convert edge to csv row
        Columns: Source, Target, timeset, remaining headers...
        """
        # initialize empty list for each header
        columns = {header:[] for header in headers}

        # collect time-value-pairs for each header
        for time,values in self.timeValues.items():
            for header,value in values.items():
                columns[header].append((time,time+1,value))

        # first rows: Source, Target
        row = [str(self.src), str(self.target)]

        # timeset format: <[time1,time1+1);[time2,time2+1);...;[timeN,timeN+1)>
        row.append('<{}>'.format(';'.join(['[{:d},{:d})'.format(time,time+1) for time in self.timeValues.keys()])))

        for header in headers:
            # print each column in format: <[time1,time1+1,value1);[time2,time2+1,value2);...;[timeN,timeN+1,valueN)>
            row.append('<{}>'.format(';'.join(['[{:d},{:d},{})'.format(*interval) for interval in columns[header]])))

        return row

# ---------------------------------------------- Script ---------------------------------------------

graphNodeStartPos = []
graphEdgeStartPos = []
graphEndPos = []

# parse file
with open(graphFile) as f:
    lines = f.readlines()

# get lines containing markers
for i,line in enumerate(lines):
    if graphNodeStartStr in line:
        graphNodeStartPos.append(i)
    elif graphEdgeStartStr in line:
        graphEdgeStartPos.append(i)
    elif graphEndStr in line:
        graphEndPos.append(i)

# check that all markers appear equally often
if (not len(graphNodeStartPos) == len(graphEdgeStartPos) == len(graphEndPos)):
    print('Error: number of markers not equal! Node {:d}, Edge {:d}, End {:d}.'.format(len(graphNodeStartPos), len(graphEdgeStartPos), len(graphEndPos)))
    sys.exit(1)

numGraphs = len(graphNodeStartPos)
graphPos = [(graphNodeStartPos[i], graphEdgeStartPos[i], graphEndPos[i]) for i in range(numGraphs)]

# check that all markers repeatedly appear in order: node, edge, end
if (not all([node < edge < end for (node, edge, end) in graphPos])) or (not all([(graphEndPos[i-1] < graphEdgeStartPos[i]) for i in range(1,numGraphs)])):
    print('Error: unexpected order of markers!')
    sys.exit(1)


# ------ read all graphs ------
nodes = {}
nodeHeaders = set()
edges = {}
edgeHeaders = set()
for i,(nodeStart, edgeStart, graphEnd) in enumerate(graphPos):
    print('Graph found from line {:d} to {:d}'.format(nodeStart, graphEnd))

    # ----- read nodes -----
    nodesReader = csv.reader(lines[nodeStart+1:edgeStart], delimiter=',', quotechar='"')

    # find index labels
    header = next(nodesReader)
    for c,column in enumerate(header):
        if column == labelStr:
            labelIndex = c
        else:
            nodeHeaders.add(column)

    for row in nodesReader:
        if (row):
            # get values of current row
            values = { }
            for c,column in enumerate(header):
                value = row[c]

                # get Label seperately. Rest in dict values.
                if c == labelIndex:
                    label = value
                else:
                    values[column] = value

            nodeId = getID(label)

            # create new node if not already
            if not nodeId in nodes:
                nodes[nodeId] = GraphNode(label)

            nodes[nodeId].timeValues[i] = values

    # ----- read edges -----
    edgeReader = csv.reader(lines[edgeStart+1:graphEnd], delimiter=',', quotechar='"')

    # find index of src and target
    header = next(edgeReader)
    for c,column in enumerate(header):
        if column == sourceStr:
            srcIndex = c
        elif column == targetStr:
            targetIndex = c
        else:
            edgeHeaders.add(column)

    for row in edgeReader:
        if (row):
            # get values of current row
            values = { }
            for c,column in enumerate(header):
                value = row[c]

                # get Source and Target seperately and convert them to unique ids. Rest in dict values.
                if c == srcIndex:
                    src = getID(value)
                elif c == targetIndex:
                    target = getID(value)
                else:
                    values[column] = value

            # let src the node with the lower index
            if (target < src):
                src, target = target, src

            # create new edge if not already exists
            if not (src,target) in edges:
                edges[src,target] = GraphEdge(src, target)

            edges[src,target].timeValues[i] = values


# convert header sets to lists
nodeHeaders = list(nodeHeaders)
edgeHeaders = list(edgeHeaders)

# Labels are used configuration: e.g. {Container: LinkedCells , CellSizeFactor: 2.000000 , Traversal: c08 , Data Layout: AoS , Newton 3: disabled}
# Extract header names
labelHeaders = list(getLabelDict(nodes[0].label).keys())

# ---- Write files ----

# create output directory
try:
    os.makedirs(outputDir)
except OSError:
    print('Could not create the output directory: ' + outputDir)
    sys.exit(2)

allNodeHeaders = [idStr, labelStr, timesetStr] + labelHeaders + nodeHeaders
allEdgeHeaders = [sourceStr, targetStr, timesetStr] + edgeHeaders

if (fullSearchFile):
    # if fullSearchFile given, append time found in this file to each row

    with open(fullSearchFile) as f:
        fullSearchLines = f.readlines()

    with open(os.path.join(outputDir, nodesFile), 'w', newline='') as f:
        nodesWriter = csv.writer(f, delimiter=',', quotechar='"')
        nodesWriter.writerow(allNodeHeaders + [fullSearchTimeStr])
        for node in nodes.values():
            row = node.getRow(nodeHeaders, labelHeaders)

            # extract label from row and find corresponding runtime in fullSearchFile
            runtime = getStringFromLines(fullSearchLines, node.label + '.* Reduced value: ([0-9]+)')

            # append runtime to row if found otherwise discard row
            if runtime:
                row.append(runtime)
                nodesWriter.writerow(row)

else:
    # without fullSearchFile just write lines into file
    with open(os.path.join(outputDir, nodesFile), 'w', newline='') as f:
        nodesWriter = csv.writer(f, delimiter=',', quotechar='"')
        nodesWriter.writerow(allNodeHeaders)
        for node in nodes.values():
            nodesWriter.writerow(node.getRow(nodeHeaders, labelHeaders))

# write edges into file
with open(os.path.join(outputDir, edgesFile), 'w', newline='') as f:
    edgeWriter = csv.writer(f, delimiter=',', quotechar='"')
    edgeWriter.writerow(allEdgeHeaders)
    for edge in edges.values():
        edgeWriter.writerow(edge.getRow(edgeHeaders))